\chapter{相关工作}
\label{chap:relatedwork}
在本章，我们介绍本课题用到的或借鉴的一些相关的工作。首先我们介绍了经常用于加密安全领域的RSA Accumulator\upcite{goodrich2002efficient}以及与之相关的用于集合元素存在性验证的Membership Witness和Nonmembership Witness。其次，我们介绍了使用RSA Accumulator和Membership Witness、Nonmembership Witness来验证集合求交集计算正确性的方法。最后我们介绍了一种基于单向加密哈希的查询验证机制。该机制通过向云服务商发送Challenge-Token的方式，使得云服务商不得不进行真实的查询计算才能保证通过用户的验证。该机制提供的是一定概率上的正确性保证。

\section{RSA Accumulator}
在文章\cite{benaloh1994one}中，Benaloh和De Mare首次提出了One-way Accumulator的概念。One-way Accumulator主要是用来将一个集合的所有元素累积到一个比较小的值，同时该值保有了一定的原集合的信息，可以用来做一些集合属性的验证。

本课题使用的验证系统是基于一种特别的One-way Accumulator：RSA Accumulator\upcite{goodrich2002efficient}.
RSA Accumulator是One-way Accumulator\upcite{benaloh1994one}的一种直观的扩展。它可以用来计算集合的Membership Witness(用于证明一个元素属于一个集合)和Nonmembership Witness(用于证明一个元素不属于一个集合)。在强RSA假设的保证下\upcite{baric1997collision}，人们是无法在有限计算资源下伪造出这些Witness的。我们取整数k为加密强度参数，k越大则加密级别越高。令 $l = \lfloor k/2 \rfloor - 2$，并令 $\chi_k$ 为集合$\mathbb{Z}_{2^l}$中的质数元素的集合，取$n = pq$为长度k的随机的模数，其中p和q是两个长度相等的安全质数。

取集合$\chi_k$的一个子集X = \{$x_1, x_2, ... , x_{|X|}$\}作为输入集合，那么集合X的每个元素就都是质数，并取g为n的一个随机的二次剩余模量。那么集合X的Accumulator为:
\begin{equation} c = g^{\prod_{i = 1}^{|X|} x_i}\ mod\ n \end{equation}

我们可以把这个Accumulator理解成类似集合的指纹。任何人在不得知p和q的情况下，是无法在多项式时间内找到另一个集合$Y \neq X$，且集合Y的Accumulator也是c。这个性质可以由强RSA假设来保证的。如果有人能做到找到这样的集合，就说明他已经突破了强RSA假设。目前来说，强RSA假设用于了众多的安全加密领域，表明它还是足够安全的。

对于集合元素$x_j$，它的Membership Witness为：
\begin{equation} \label{eq:sw} c_{x_j} = g^{\prod_{i=1, i \ne j}^{|X|} x_i}\ mod\ n \end{equation}

如果我们要验证$x_j \in X$的话，只需要验证$(c_{x_j})^{x_j} = c\ mod\ n$是否成立。

对于一个属于$\chi_k$却不属于集合X的元素x，它的Nonmembership Witness为一个二元组(a,d)\upcite{li2007universal},其中a和d满足：
\begin{equation} c^a = d^x\ mod\ n\end{equation}

以上说的Membership Witness和Nonmembership Witness都是针对单个元素的，如果需要一次验证多个元素，那么我就就需要计算多个Witness并进行多次验证，这显得非常效率低下。为了处理多个元素的情况，以上的方法被稍微进行一些如下扩展，使之可以用作多个元素的Membership Witness和Nonmembership Witness。

我们取X的子集$X^{\prime} = \{x_{i_1}, x_{i_2}, ... , x_{i_{|X^\prime|}}\}$， 那么$X^\prime \subseteq X$的Membership Witness为:
\begin{equation} \label{eq:w} c_{X^\prime} = g^{\prod_{x \in X - X^\prime} x}\ mod\ n \end{equation}

有了这个Membership Witness，我们如果要证明$X^\prime \subseteq X$ 只需要验证下面这个式子是否成立:
\begin{equation} \label{eq:vw} c_{X^\prime}^{\prod_{x \in X^\prime} x} = c\ mod\ n\end{equation}
从式子\ref{eq:vw}可以看出，对于$X^\prime \subseteq X$的验证，我们所需要关于集合X的信息只有它的Accumulator c，而不用知道它的别的信息，比如它包含哪些元素。

我们另取集合 $Y = \{y_1, y_2, ... , y_{|Y|}\}$，它的每个元素$y_i$都是质数，且 $Y \bigcap X = \phi$。那么集合Y相对于X的Nonmembership Witness是这样一个二元组(a, d) 其中
$au + bv = 1, d = g^{-b}\ mod\ n$，这里 $u = \prod_{x \in X} x, v = \prod_{y \in Y} y$。

如果我们要证明 $Y \bigcap X = \phi$，只需要验证下式是否成立：
\begin{equation} \label{eq:vnw} c^a = d^v g\ mod\ n \end{equation}

\section{集合交集的证明}
有了上一个小结介绍的Accumulator和Witness, 我们在这里介绍一种方法，可以用它们来生成集合交集是否正确的证明以及相应的验证方法。比如说有个用户要求计算两个集合$X_1$和$X_2$的交集，然后云端就计算了 $X = X_1 \bigcap X_2$返回给用户，同时返回由X分别属于$X_1$和$X_2$的Membership Witness组成的正确性证明。由于Membership Witness是无法伪造的，用户可以通过等式\ref{eq:vw}来验证X是不是正确的结果。

但是这里还存在一个问题，就是计算结果X可能没有包含全部的交集元素。这个时候X也满足同时属于$X_1$和$X_2$，可以通过用户的验证，但却不是正确的结果。这说明仅仅用正确性证明是不够的。为了处理这种只返回部分结果的情况，我们需要一个完整性证明来保证集合X包含集合$X_1$和$X_2$的交集的全部元素。也就是说($X_1 - X$)不包含任何属于集合$X_2$的元素。这样的完整性证明有以下几个部分组成:
\begin{itemize}
\item 集合$X^\prime = X_1 - X$
\item $X^\prime$属于$X_1$的Membership Witness
\item $X^\prime$不包含任何属于$X_2$的元素的Nonmembership Witness
\end{itemize}

用户可以通过等式\ref{eq:vnw}来验证Nonmembership Witness。在验证了正确性证明和完整性证明后，用户需要验证$X + X^\prime = X_1$来保证$X^\prime$的正确性。这个验证可以通过计算$X + X^\prime$这个集合的Accumulator，然后与集合$X_1$的Accumulator进行比较。如果相等，则说明$X + X^\prime = X_1$成立。

上面我们讲了两个集合交集的证明，简单扩展下就可以用于多个集合。对于m个集合的交集 $X = X_1 \bigcap X_2 \bigcap ... \bigcap X_m$。正确性证明还是和两个集合的情况一样，只是变成需要m个Membership Witness。至于完整性证明的话，我们还是选$X^\prime = X_1 - X$，那么我们需要证明$X^\prime$的每个元素至少不属于$X_2, X_3,...,X_m$中的一个。也就是说，我们需要对$X^\prime$的每个元素计算一个Nonmembership Witness。考虑到每个集合含有元素的多少可能会有较大的差异，我们可以选择含有元素最少的集合代替$X_1$来计算$X^\prime$，这样得到的$X^\prime$也是含有最少的元素数目，这样我们需要的Nonmembership Witness的数目也是最少的。

\section{一种基于加密哈希的查询验证方式}
哈希算法是一种将任意长度的数据映射到固定长度数据的一种算法，而且输入数据的细微改变都会导致输出的巨大差异。单向加密哈希(One-way Cryptographic hash)\upcite{CHash}是指哈希算法里面被认为无法进行逆运算的那一类，也就是说无法从给定的哈希值中计算出原来的输入数据是什么。由于这种不可逆性，单向加密哈希在信息安全领域里有着众多应用，比如数字签名、信息认证以及各类形式的认证。

\myfig{chash.eps}{3.5in}{一种数据委托模型\upcite{sion2005query}}{chash}{Database Outsourcing Overview\upcite{sion2005query}}
文章\cite{sion2005query}中就提出了一种基于加密哈希的查询验证方式。如图\ref{fig:chash}中所示，数据拥有者把他的数据委托给数据服务商来进行管理。数据拥有者对数据进行的任何操作都是通过数据服务商提供的接口进行的，因此数据拥有者无法得知数据服务商的内部操作是不是正确执行的。

考虑这样一个场景，数据拥有者发送了b个查询 $\mathbb{Q} = \{Q_1, Q_2, ... ,Q_b\}$给数据服务商。
数据服务商收到这个查询之后，执行了查询过程，然后给数据拥有者返回了结果$\{\rho(Q_1), \rho(Q_2), ..., \rho(Q_b)\}$。

对于一个恶意的服务商，它可能为了节省自己的计算资源，随意地伪造查询结果，或者只是计算了部分的查询。

参考了ringers\upcite{golle2001uncheatable}的设计思路，作者提出了使用Challenge-Token来验证数据服务商的返回结果。

对每一批查询$\mathbb{Q} = \{Q_1, Q_2, ... ,Q_b\}$, 数据拥有着随机选择一个只有自己知道的数 $x \in [1, b]$，同时选择一个一次性的随机数$\epsilon$，然后用它们计算出一个Challenge-Token:
\begin{equation} C(\mathbb{Q}, x, \epsilon) = \{H(\epsilon \parallel \rho(Q_x)), \epsilon\}\end{equation}
这里，$\parallel$表示按位连接，H是一个单向加密哈希函数。

也就是说，数据拥有者在发送查询前，先随机挑选了一个查询，然后在本地计算出查询结果，然后使用加密哈希函数对该结果以及一个随机值进行计算，计算出一个无法进行逆运算的值。
在发送查询的时候，数据拥有者把Challenge-Token值、随机数$\epsilon$值和$\mathbb{Q}$一起发送给服务商，并要求服务商在返回查询结果的同时，返回这个Challenge-Token值是由那个查询计算得出的，也就是x值。

当数据服务商收到这个请求时，由于单向加密哈希的不可逆性，数据服务商无法直接从Challenge-Token值中计算出它对应的查询$Q_x$。为了返回正确的x值，数据服务商只能对数据拥有者发来的查询进行一个一个地执行，然后对这些查询结果进行同样的单向哈希计算。这样对于每一个查询，服务商就都计算出了一个值，然后用这些值去和数据拥有者发来的Challenge-Token去一一比较，就可以找出这个Challenge-Token是哪一个查询计算出来的。

在数据拥有者收到了服务商返回的查询结果$\rho(\mathbb{Q}) = \{\rho(Q_1), \rho(Q_2), ..., \rho(Q_b)\}$和相应查询编号$x^\prime$(也就是对应x的值)。在不考虑服务商的$x^\prime$值是猜的情况下，数据拥有者检查($x^\prime = x$)是否成立。如果成立，说明服务商是执行了正确的查询的。这是因为服务商能提供正确的x值，要么是对计算Challenge-Token用到的单向加密哈希进行了逆运算(这是不可能的)，要么就是执行了这一批查询，然后在结果中找出哪一个符合这个Challenge-Token。

在计算Challenge-Token的时候，这里用到了一个随机数$\epsilon$。这是因为对于一个比较智能的服务商，在没有随机数的情况下，它可以记住每次出现的Challenge-Token。如果有足够的存储空间，服务商就可以把之前遇到的Challenge-Token和对应的查询都记下来，比如存成一个便于查询的哈希表。随着服务商存储下来的Challenge-Token越来越多，那么遇到新的查询的时候，服务商就可以直接在哈希表里面找这个查询的Challenge-Token，而不需要真的去进行查询计算了。
也就是说，如果数据拥有者恰好使用了同一个Challenge-Token两次，那么第二次的时候，服务商就可以直接返回对应的x值，而不需要进行查询计算了。而当生成Challenge-Token的时候加上了一个唯一的随机数时，就算是同一个查询，它们的Challenge-Token还和这个随机数有关，这基本上是不会相同了。这样，就算服务商将遇到过的Challenge-Token记录下来也没有用了。

上面提到了，这个方法提供的是一个统计意义上的保证，那么服务商有多少的概率可以成功地欺骗数据拥有者呢？如果服务商采用部分计算的方式，比如只计算其中的$0 \le w < b$个查询，然后在这些查询里面试着找出与Challenge-Token对应的那个。如果在这个w个查询中，那个对应的查询没有找到，服务商就简单地在剩下的那些查询里面随机猜测一个。那么服务商返回正确的x值得概率为:
\begin{equation} P(w) = \frac{w}{b} + (1 - \frac{w}{b})\frac{1}{b-w} = \frac{w + 1}{b} \end{equation}

这是一个关于w的线性函数，这说明服务商欺骗成功的概率和他所进行的查询数目是成正比的。也就是说，服务商想要干很少的活，那么欺骗成功的概率就变低；服务商想要欺骗成功的概率变高，那么他就需要干更多的活。对于服务商来说，它没办法找到一种两全其美的办法。而且在多次查询之后，每次欺骗全都成功的概率会随着查询次数的增加而减少。在有足够多的查询次数的情况下，服务商每次都成功欺骗，而不被数据拥有者发现的概率可以任意的小。

但是我们可以发现，只是简单地使用客户端验证的方法，就能取得差不多的保证概率。比如说，对于一次总共有b个查询的请求，数据拥有者不再计算出一个Challenge-Token，而是在服务商返回的结果里面随机选择一个，然后在本地进行一次这个查询，最后比较下自己计算的结果和服务商返回的结果是否一致。相比较Challenge-Token的方式，这个客户端验证的方式有着差不多的网络带宽消耗，却减少了服务端计算Token的过程，而且客户端的计算量也没有增加(计算Challenge-Token也要进行一次本地搜索)。在客户端验证方式下，服务商在只完成了$0 \le w < b$个查询的情况下成功不被客户发现的概率为：
\begin{equation} P_c(w) = \frac{w}{b} \end{equation}

这个概率和使用Challenge-Token的方式的概率P(w)基本是一致的。那么为什么还要采用这个更加费计算的Challenge-Token方式呢？

文章中先把Challenge-Token方式做了个扩展，在原来只使用一个Challenge-Token的基础上改为使用r > 1个Challenge-Token。那么服务商在只计算w < b个查询的情况下，成功返回r个正确的查询编号从而成功骗过客户端的概率是多少呢？假设服务商的策略是在完成的w个查询里面找对应的Challenge-Token，有多少找多少。对于没有找到的Challenge-Token，它就在剩下的那些查询里随机地猜。这样，服务商在w个查询里面成功找到x个Challenge-Token的概率为:
\begin{equation} P_0(b, w, r, x) = \frac{\binom{r}{x} \times \binom{b-r}{w-x}}{\binom{b}{w}} \end{equation}
这里，$x \in [max(0, w+r-b), min(r,w)]$。还有，在b个查询里面随机猜对r个的概率为:
\begin{equation} P_1(b,r) = \frac{1}{\binom{b}{r}} \end{equation}
最后，服务商成功在计算w<b个查询的情况下，成功骗过客户端的概率为:
\begin{equation} P(w,r) = \sum_{i=max(0,w+r-b)}^{min(r,w)} [P_0(b,w,r,i) \times P_1(b-w,r-i)] = \frac{1}{\binom{b}{r}}\sum_{i=max(0,w+r-b)}^{min(r,w)}\binom{w}{i} \end{equation}

\myfig{pro.eps}{3.5in}{b = 20情况下的一些P(w,r)值\upcite{sion2005query}}{pro}{The behavior of P(w,r) with b = 20\upcite{sion2005query}}
如图\ref{fig:pro}所示，在增加了Challenge-Token之后，服务商要达到同样的欺骗成功概率就需要执行多得多的查询。比如说，对于20个查询和3个Challenge-Token的情况，如果需要达到40\%的欺骗成功率，那么服务商至少需要执行其中的14个查询。而当只有一个Challenge-Token时，它只需要执行7个查询。

当然，客户端检测的方式也同样可以使用增加检测的查询数目来降低被服务商欺骗成功的概率。假设客户端选择了$1 < r \le w$个查询结果进行检查，那么被服务商成功欺骗的概率为：
\begin{equation} P_c(w,r) = \frac{\binom{w}{r}}{\binom{b}{r}} \end{equation}
与P(w,r)比较可以得出，$P_c(w,r) \le P(w,r)$，也就是说多个Challenge-Token的方式也没有比客户端方式有着更高的正确性保证。而且Challenge-Token方式还有一个问题，就是服务商可以采用依次进行查询，查询一次就找一次Challenge-Token，直到所有Challenge-Token都被找到，然后对剩下的查询不再计算，而是随机编造结果。这样的话，服务商就可以减少计算量，且每次都能骗过数据拥有者。

这些问题可以通过增加假Challenge-Token来解决。之前的情况下服务商都是确切知道有多少个Challenge-Token的，这给了它很好的猜测基础。我们可以通过引入假Challenge-Token来避免这种情况，从而降低服务商欺骗成功的概率。

假Challenge-Token是一个随机伪造的和Challenge-Token有同样格式的数字，但是却不是真实的从查询结果计算的。它会和Challenge-Token一起发给服务商，要求服务商在返回时对于Challenge-Token要返回对应的查询编号，对于假Challenge-Token则返回空查询。

增加假Challenge-Token之后，服务商在执行完所有查询之前，就不能知道这些Challenge-Token哪些是真哪些是假。这样，如果服务商想百分百保证不被发现欺骗，那么它就只能执行全部的查询而无法像之前一样偷懒只进行部分计算。

在增加了假Challenge-Token之后，服务商如果还是要在只计算w < b个查询的情况下伪造结果试图骗过数据拥有者，那么它需要猜测哪些Challenge-Token是真的，这时成功欺骗的概率为:
\begin{equation}P^\prime(w,r,f) = \frac{1}{\binom{b}{r}}\sum_{i=max(0,w+r-b)}^{min(r,w)}[\frac{\binom{w}{i}}{min(b-w,max(1,r+f-i))}]\end{equation}

\myfig{allpro.eps}{3.5in}{几种方式的概率比较\upcite{sion2005query}}{allpro}{The behavior of different method\upcite{sion2005query}}

图\ref{fig:allpro}中给出了前面提到的几种方式的概率比较。从图中我们可以看出，在增加了2个假Challenge-Token的时候，服务商成功欺骗的概率相比$P_c(w,r=2)$已经降低了一半，而且通过再增加假Challenge-Token，可以进一步降低这个概率。而且增加一个假Challenge-Token只需要随机生成一个数据，代价是很小的。

从前面的介绍我们可以看出，这种基于单向加密哈希的查询验证方法有着简单的原理，可以方便地进行实现。而且相比于客户端验证方式，该方法有着更高的验证成功率。文章\cite{sion2005query}中的实验评估数据也表明这个方法给查询系统带来的额外负担是很低的。但是该方法的缺点也很明显：一是，不能百分百地完全保证正确性；二是，只能是几个查询一起进行，不能进行单个的查询；最后是，不能防止服务商在执行全部查询之后还是恶意地返回错误结果。

\section{本章小结}
本章介绍了本课题相关的已有研究。主要是介绍了用于集合元素存在性验证的RSA Accumulator和Membership Witness、Nonmembership Witness。RSA Accumulator是将集合的每一个元素按照一定的函数计算得到的一个值。这个对于集合可以说是像指纹一样独一无二。在Accumulator的基础上，Membership Witness和Nonmembership Witness可以提供集合元素存在性和不存在性的验证功能。
接着我们介绍了一个通过Membership Witness和Nonmembership Witness来验证集合求交集运算正确性的方法。该方法主要是将求交集的证明分为正确性证明和完整性证明两部分。然后使用Membership Witness来进行正确性证明，使用Nonmembership Witness来进行完整性证明。

本章还介绍了一种基于单向加密哈希的查询验证方法。该方法的主要思路是在向云服务商提交查询前先计算出某一个查询的结果，并对该结果加密。然后在发送查询的时候，把加密值也发送给云服务商，并要求云服务商返回这个加密值是哪个查询计算出来的。这样，云服务商就只能进行全部查询才能知道这个加密值是哪个查询的。该方法虽然不能百分百地保证云服务商的正确性，却可以让用户在只需要付出很小的额外负担下，很大概率保证不被云服务商欺骗。

