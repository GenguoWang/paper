\chapter{设计与实现}
\label{chap:design}


本章我们将介绍云搜索正确性的快速验证系统的整个系统构造。首先，我们会介绍该系统的整体框架，介绍它是有那些部分组成的，每个部分是什么功能的以及各个部分之间是怎么交互的。然后，我们会介绍整个系统里面一些重要的细节，比如为了提升整体效率而设计的一些方案，比如树状的证明结构。

\section{系统的整体架构}

我们使用了第\ref{chap:relatedwork}章介绍的验证机制来进行云搜索的正确性验证。按照该验证机制的特点，我们进行了有针对性的系统设计。该验证机制包含两个角色，数据拥有着(用户)和云服务商。对此，我们将系统划分为客户端和服务端。在云端，我们需要完成索引的查询以及搜索结果的生成等操作，我们按照功能进行了相应的模块划分。

在我们的系统里，每个模块都是一个可以单独启动的进程，模块之间使用HTTP协议进行交互。采用这样设计的原因主要是：1. 采用单独的进程可以让每个模块进行单独的部署，而不需要都部署到一台机器，这样使得系统有比较好的可扩展性，2. HTTP是一种使用得非常广泛也非常易于使用的协议，采用HTTP可以让我们的系统可以更加容易进行调试也方便了一些扩展模块的开发。

具体的，考虑到高可靠性，扩展性，高可维护性的要求，我们将系统分为了Index Generator, Search Client, Search Server, Query Node, Correctness Server, Integrity Server, Prime Manager这几个组成部分。下面，我们对这几个组成部分分别进行介绍。

\myfig{framework.eps}{3.5in}{系统的整体框架 }{des:structure}{Structure of system}

\subsection{Index Generator}
Index Gnerator是一个单独的工具，它不需要和别的模块进行交互。它主要负责的对于一个文本的集合进行可验证索引的建立操作。我们采用了Indri Indexer\cite{Indri}来生成倒排索引。在生成了倒排索引之后，我们从中抽取出我们需要的内容，用来生成可验证索引。对于生成的可验证索引，我们以文件的形式存储到磁盘上。索引的数据比较大，为了减少单个文件的体积，同时也为了方便使用多模块处理，我们将索引数据使用一致性哈希的方式存储到多个文件中。生成的索引数据文件组织如下：
\begin{itemize}
\item \textbf{meta.txt} 存储索引数据的元信息，包括索引版本、文档总数目、Term总数目、索引文件的数目、平均的文档长度等信息。
\item \textbf{term\_map.txt} 存储Term到Term ID的映射。
\item \textbf{ch\{0,1,..,M\}.txt} M个文件。M由用户指定。存储所有Term ID到(docID, w)的映射。我们使用Term的SHA1值作为Key，然后使用一致性哈希将其分配到对应的ch.txt文件。如果各个文件的索引数目不均匀，我们可以采用加大M值的方式来解决。
\end{itemize}

\subsection{Search Client}
Search Client是负责发起搜索任务并对搜索结果进行验证的模块。该模块接受用户的输入，然后把该搜索关键词发送到Search Server进行查询。在服务端返回结果后，Search Client可以对该结果以及随结果返回的证明进行验证，以此来判断该结果是否正确。

\subsection{Search Server}
Search Server: 如其名所言，是负责接收搜索任务的模块。该模块接收从Search Client发送过来的搜索请求，对该搜索请求进行一些初步处理，比如去除一些无关词语，然后会把本次搜索的关键词发送到各个Query Node。每一个Query Node会返回他们拥有的和本次搜索结构相关的索引内容。在各个Query Node返回它们的查询结果后，Search Server会对这些结果进行整合，这样就得到了一个完整的搜索结果。然后，Search Server会把这个结果分别发送到Correctness Server和Integrity Server去进行证明的计算。等到证明计算完成，Search Server就把搜索结果和证明一起返回给客户端。到这里，本次搜索的过程就结束了。

\subsection{Query Node}
Query Node是负责的索引查询的模块。在我们的系统中，索引被按照一致性哈希的方式分成了M份。如果我们有N个Query Node, 我们用0，1，2…N-1进行编号。编号为i的Query Node负责编号为i, i+N, i+2*N,…的索引文件。当一个查询到来的时候，Query Node查询自己负责的那部分索引里面是否有本次搜索包含的关键词部分，如果有就返回相应的内容，如果没有就告知没有。

\subsection{Correctness Server}
Correctness Server是计算正确性证明的模块。Correctness Server使用了稍后会介绍的树状证明结构。该结构能够将正确性计算从一次非常耗时的计算分解成多个可以快速计算的小任务，以此来充分利用计算机集群以及多个CPU核来加快计算的速度。

\subsection{Integrity Server}
Integrity Server: 计算完整性证明。该计算与正确性证明是同时进行的，来加快整个证明的计算速度。
在我们的系统中，每个模块都是单独的进程。模块这件是通过HTTP协议进行通讯，所以各个模块可以随意的部署到不同的机器，这样可以充分利用整个计算机集群，以提供非常不错的可扩展性。

\subsection{Prime Manager}
Prime Manager这个模块的作用是使用事先计算好的质数表示来加快搜索结果的证明的计算。在证明的计算里面，我们需要使用到文档编号，索引数据，Term ID等元素的质数表示。计算质数表示是一项比较费时间的计算，而且在我们的系统中有着非常高的使用频率，且包含很多重复计算的情况。所以，我们采用了事先计算的方式来避免在在计算质数表示上浪费时间。我们对每一个文档编号，每一个Term的索引数据都事前计算好质数表示，存储到文件中。在系统使用时，只需要到Prime Manager查询相应的质数表示，而不再需要进行繁重的计算。

在事先计算质数表示时，对于大的数据集，我们使用MPI开发了一个程序来进行并行计算。在并行计算的任务划分中，由于每个Term的索引数据的大小并不一致，我们没有简单的按照Term进行任务划分，而是按照索引条目进行任务的划分。从系统的运行情况来看，按照索引条目进行划分的策略确实加快了这个计算过程。

\section{树状证明}
在我们系统设计的初期，我们只是简单的使用并行计算正确性索引和完整性索引来加速证明的计算。经过一些测试之后，我们发现这个计算速度还比较慢。对于一些文档集合比较大的搜索结果，生成证明的时间可以高达几十秒。在使用了性能调优工具进行性能瓶颈检测后，我们发现正确性证明的生成占用了大部分的计算时间。在经过一些了调查和尝试之后，我们设计并实现了树状证明结构来加快正确性证明的计算。

\subsection{树状证明的设计}

\myfig{tree.eps}{3.5in}{由20个文档组成， e = 4的树状结构}{des:tree}{Tree structure with 20 documets and e = 4}
我们取 D = \{$d_1$\, $d_2$, ..., $d_n$\}表示某个关键词的倒排索引里面的文档集合。
我们取D的子集 S = \{$d_{i_1}$, $d_{i_2}$, ..., $d_{i_m}$\}，那么公式提的方法，我们要计算S属于D的Membership Witness的话，我们将近需要对集合D里面的每一个元素进行累乘，然后进行一次乘方计算。
在我们的设计里面使用了GMP这个库进行高精度数学计算。经过测试，我们发现连续乘方的速度比先累乘的速度要快很多。于是我们就采用了连续乘方的方式。但连续乘方这样的计算方式有一个问题，那就是计算步骤是相互依赖的，于是没法使用并行计算进行加快。
文章\ref{papamanthou2008authenticated}提出了一种RSA树的结构用来进行高效的集合元素的存在性证明。我们在其基础上设计了树状证明这样的结构。
我们取e为大于1的整数，对于文档集合D，我们对其进行树状结构的构建。为了便于描述，我们把这样的树叫做T(e, D),它有如下的特点:
\begin{enumerate}
  \item T(e, D) 是一颗三层的树
  \item 叶子节点保存文档的质数表示。第i叶子节点保存对应文档$d_i$的质数表示。
  \item T(e, D) 有 m = $\lceil \frac{m}{e} \rceil$ 中间层节点。第i个中间层节点 $m_i$ 存储它所有子节点组成集合的Accumulator。
  \item 除了最后一个中间层节点，每个中间层节点有且仅有e个子节点。最后一个中间层节点有不多于e个的子节点。
\end{enumerate}

对于这样的结构，我们如果要证明某个叶子存在，可以先证明它属于某个中间层节点，然后再证明这个中间层节点存在，也就是证明这个中间层节点属于根节点。按照这个思路，我们取M = \{$m_0, m_1, ..., m_{m-1}$\},G($m_i$) = \{$d_j$ | $d_j$ 是 $m_i$的子节点 \}, 取D的子集S = \{$d_{i_1}$, $d_{i_2}$, ..., $d_{i_m}$\}。 那么我们对于 $S \subseteq D$ 是如下这样:
\begin{enumerate}
  \item 把S拆分成 $S_0$, $S_1$, $S_{m-1}$，其中 $S_i$ = $S \bigcap G(m_i)$。 也就是说 $S_i$ 包含S中的那些属于第i个中间层节点的元素。
  \item 对于每个非空的 $S_i$, 我们计算 $S_i \subseteq G(m_i)$的证明: $p_i = g^{\Pi_{\mu \in G(m_i) - S_i} r(\mu)}\ mod\ N$, 这里 $r(\mu)$ 是 $\mu$的质数表示。 
  \item 对于每个非空的 $S_i$, 我们计算 $m_i \in M$的证明:$q_i =  g^{\Pi_{\mu \in M, \mu \ne m_i} r(\mu)}\ mod\ N$
  \item 我们的树状证明由全部的$(S_i, p_i, q_i, m_i, a)$元组组成 , 这里的a是集合M的Accumulator.
\end{enumerate}

有了这样的树状证明，我们就可以按照以下步骤进行验证:
\begin{enumerate}
  \item 检查 $\cap S_i = S$来证明S中的每个元素都没有遗漏，都包含在了证明中。
  \item 检查 $p_i^{\Pi_{\mu \in S_i} \mu} = m_i\ mod\ N$来证明 $S_i \subseteq G(m_i)$
  \item 检查 $q_i^{m_i} = a$ 来证明 $m_i in M$
  \item 检查 a 是否和客户自己计算并保存在本地的一样，一次来保证这个树状结构不是云端随意构造的
\end{enumerate}

使用树状证明的好处是：1. 对于$S_i$是空集的情况，我们是不需要进行计算的。2. 我们在将S划分成$S_0$, $S_1$, $S_{m-1}$之后, 对$S_i$它们进行的计算是没有相互依赖关系的，我们可以使用并行计算来进行加速。在我们的系统中，我们设计了一个叫Worker任务分配机制的计算框架来进行轻量级的并行计算。而且，中间层的属于根节点的证明$q_i$可以事先计算。在整个计算过程中，我们需要计算的只有$p_i$。

树状证明有着 O(|S|) 的空间复杂度。这个和搜索结构的空间复杂度是一致的。所以树状证明不会使得整体的空间复杂度增加，是完全可以接受的。

树状结构主要是用来加快大的集合的正确性验证生成过程，而对于小的集合，树状结构由于增加了一些中间层，增加计算的复杂性，在总性能上就没有什么优势。在我们的系统中，用户可以自行选择一个阈值来决定要多大的集合才使用树状证明。

\subsection{树状结构的计算: Worker任务分配机制}
\begin{figure}[htb]
\begin{lstlisting}[language=C++] 
class JobInterface
{
public:
    virtual void readFromStream(std::istream &in)=0;
    virtual void writeToStream(std::ostream &out)=0;
    virtual std::string run()=0;
};
\end{lstlisting}
\bicaption[fig:job]{图索引}{Job的接口}{Fig}{Job's Interface}
\end{figure}

为了可以方便的利用多台机器的优势来计算树状证明，我们设计实现了轻量级的并行计算框架：Worker任务分配机制。任务的最小单元为Job，其接口如图\ref{fig:job}所示。
每一个计算单元叫做Processor，它可以接受来自别的Processor或者任务发起的输入，然后返回计算结果。
有两种特殊的Processor，一种是ManageProcessor，另一种是WorkerProcessor。
ManageProcessor起任务分配，结果汇总的作用。接受任务发起者的输入，然后把任务分派给别的Processor，等每个Processor的返回了任务结果之后，它把所有结果汇总，返回给任务发起者。
WorkerProcessor的作用就是完成一个或多个Job的计算。它从自己的输入流里面读入Job，然后进行Job的计算，最后返回计算结果。
\begin{figure}[htb]
\begin{lstlisting}[language=C++] 
class ProofCalcJob:public JobInterface
{
protected:
    typedef std::set<NTL::ZZ> SetType;
    typedef SetType::iterator SetItType;
    SetType primeAll;
    SetType primeSubset;
public:
    void readFromStream(std::istream &in){...}
    void writeToStream(std::ostream &out){...}
    virtual std::string run()
	{
        ostringstream oStr;
        oStr << RSAAccumulatorService::getRSAAccumulator()->publicGenSubsetProof(primeAll, primeSubset);
        return oStr.str();
	}
}
\end{lstlisting}
\bicaption[fig:job]{图索引}{计算证明的Job}{Fig}{Job for computing proof}
\end{figure}
\section{基于概率的验证}
我们的系统在证明生成上的效率相比原来的方法有了不少提升。但对于那些对证明要求不高的使用场景，每次搜索的时候都要去计算证明的话，是比较浪费计算资源，也增加了用户的等待时间，是得不偿失的。

对于那样的场景，我们提出了一种基于概率的验证方式。对于搜索，我们提供两种模式，一种是非验证搜索，该种模式下服务端只需要返回搜索结果，无需进行证明的生成，另一种是验证搜索，该种模式下服务端要同时返回结果以及证明。

假设云服务商的搜索不是完全正确的，假设其错误概率为p。在一般情况下，我们使用非验证搜索这个效率更高，使用资源更少的搜索方式。比如说我们进行了n次非验证搜索。这时由于没有证明，我们是不知道云服务商给的结果是否是正确的。然后我们在这n非验证搜索里面抽取m次进行验证搜索。

为了防止云服务商对于验证搜索时给正确结构，而非验证搜索时给错误的结果，我们首先要比较验证搜索和非验证搜索的结果，如果不一致，说明云服务上的搜索是不正确的。

在验证了两种搜索结果一致后，我们再对m个验证搜索的结果进行验证。由于云服务商的错误概率是p，那么在这m个验证中，我们发现云服务商是有问题的概率是$1-(1-p)^m$

我们在表TODO中列举了一些数据结果，从这些结果来看，我们只需要不多的检测就能有很高的概率来检测出来云服务商是否是有问题的。
\section{本章小结}
本章介绍了我们的云计算快速验证系统的设计。为了系统的易维护性和可扩展性，我们采用了分节点的设计，每个节点为单独的进程，各个节点之间使用HTTP协议交互，方便节点部署到不同的机器。为了加快证明的生成，我们设计了树状的证明结构，是的证明的计算可以多机器多进程的并行计算。为了考虑效率优先，验证不需要完全保证的情况，我们提出了一种基于概率的验证方式，使得用户可以根据需要来选择需要多少程度的验证。
